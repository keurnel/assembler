package keurnel_asm

import "fmt"

type TokenType string

const (
	ILLEGAL TokenType = "ILLEGAL"
	EOF     TokenType = "EOF"

	// Architecture-specific tokens
	INSTRUCTION TokenType = "INSTRUCTION" // e.g., MOV, ADD, etc.
	OPERAND     TokenType = "OPERAND"     // e.g., rax, [rbx], 0x10, etc.

	// Keurnel Assembly - directives and labels
	DIRECTIVE TokenType = "DIRECTIVE" // e.g., .data, .text, etc.
	LABEL     TokenType = "LABEL"     // e.g., main:, loop:, etc.
	NAMESPACE TokenType = "NAMESPACE" // e.g., namespace my_namespace { ... }

	// Symbols

	SYMBOL_COMMENT_START byte = ';'  // Start of a comment
	SYMBOL_COMMENT_END   byte = '\n' // End of a comment (newline)

	SYMBOL_DIRECTIVE_START byte = '.' // Start of a directive
	SYMBOL_DIRECTIVE_END   byte = ':' // End of a directive (newline)
)

type Token struct {
	Type    TokenType
	Literal string
}

type Lexer struct {
	input        string
	position     int
	readPosition int
	ch           byte
	tokens       []Token
}

// LexerNew - returns a new instance of the Lexer
func LexerNew(input string) *Lexer {
	l := &Lexer{
		input:        input,
		position:     0,
		readPosition: 0,
		tokens:       []Token{},
	}
	return l
}

// Tokens - returns the list of tokens generated by the lexer
func (l *Lexer) Tokens() []Token {
	return l.tokens
}

// Process - generates tokens from the input assembly source code
func (l *Lexer) Process() []Token {

	l.readChar()

	print("Value of ch: ", l.ch, "\n")

	for l.ch != 0 {
		l.skipWhitespace()

		// Break loop if we have reached the end of the input string.
		//
		if l.ch == 0 {
			break
		}

		// Skip comments (lines starting with ';')
		if l.ch == SYMBOL_COMMENT_START {
			for l.ch != SYMBOL_COMMENT_END && l.ch != 0 {
				l.readChar()
			}
			continue
		}

		// Read directives (lines starting with '.')
		//
		if l.ch == SYMBOL_DIRECTIVE_START {
			l.tokens = append(l.tokens, l.readDirective())
			continue
		}

		// Read instructions and operands
		//
		if l.isLetter(l.ch) {
			// Check if this is a namespace declaration
			if l.peekNamespace() {
				l.tokens = append(l.tokens, l.readNamespace())
				continue
			}

			// Check if this is a label (ends with ':')
			if l.peekLabel() {
				l.tokens = append(l.tokens, l.readLabel())
				continue
			}

			// Otherwise, it's an instruction
			l.tokens = append(l.tokens, l.readInstruction())

			// Read operands after the instruction
			l.skipWhitespace()
			for l.ch != 0 && l.ch != SYMBOL_COMMENT_START && l.ch != '\n' {
				if l.ch == ',' {
					l.readChar()
					l.skipWhitespace()
					continue
				}
				l.tokens = append(l.tokens, l.readOperand())
				l.skipWhitespace()
			}
			continue
		}

		// Handle illegal characters (anything that doesn't fit the above categories)
		//
		l.tokens = append(l.tokens, Token{Type: ILLEGAL, Literal: string(l.ch)})
		l.readChar()
	}

	// End of file token
	//
	l.tokens = append(l.tokens, Token{Type: EOF, Literal: ""})

	// Print tokens
	fmt.Println("Generated tokens:")
	for _, token := range l.tokens {
		fmt.Printf("Type: %s, Literal: '%s'\n", token.Type, token.Literal)
	}

	return l.tokens
}

// readChar - reads the next character from the input and advances the positions
func (l *Lexer) readChar() {
	if l.readPosition >= len(l.input) {
		l.ch = 0 // ASCII code for NUL, signifies end of input
	} else {
		l.ch = l.input[l.readPosition]
	}
	l.position = l.readPosition
	l.readPosition++
}

func (l *Lexer) skipWhitespace() {
	for l.ch == ' ' || l.ch == '\t' || l.ch == '\n' || l.ch == '\r' {
		l.readChar()
	}
}

// readDirective - reads a directive token from the input
func (l *Lexer) readDirective() Token {
	position := l.position
	for l.ch != SYMBOL_DIRECTIVE_END && l.ch != 0 {
		l.readChar()
	}

	// Remove `SYMBOL_DIRECTIVE_END` from the literal if it exists
	if l.ch == SYMBOL_DIRECTIVE_END {
		literal := l.input[position:l.position]
		l.readChar() // Consume the ':' character
		return Token{
			Type:    DIRECTIVE,
			Literal: literal,
		}
	}

	return Token{
		Type:    DIRECTIVE,
		Literal: l.input[position:l.position],
	}
}

func (l *Lexer) isLetter(ch byte) bool {
	return ('a' <= ch && ch <= 'z') || ('A' <= ch && ch <= 'Z') || ch == '_'
}

func (l *Lexer) peekLabel() bool {
	pos := l.position
	for pos < len(l.input) && l.input[pos] != '\n' && l.input[pos] != 0 {
		if l.input[pos] == ':' {
			return true
		}
		if l.input[pos] == ' ' || l.input[pos] == '\t' {
			break
		}
		pos++
	}
	return false
}

func (l *Lexer) peekNamespace() bool {
	// Check if the current word is "namespace"
	pos := l.position
	keyword := "namespace"
	for i := 0; i < len(keyword); i++ {
		if pos >= len(l.input) || l.input[pos] != keyword[i] {
			return false
		}
		pos++
	}
	// Make sure it's followed by whitespace or end of input
	if pos < len(l.input) {
		ch := l.input[pos]
		return ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r'
	}
	return true
}

func (l *Lexer) readLabel() Token {
	start := l.position
	for l.isLetter(l.ch) || (l.ch >= '0' && l.ch <= '9') || l.ch == '_' {
		l.readChar()
	}
	if l.ch == ':' {
		l.readChar()
	}
	return Token{Type: LABEL, Literal: l.input[start:l.position]}
}

func (l *Lexer) readNamespace() Token {
	// Skip "namespace" keyword
	for l.isLetter(l.ch) {
		l.readChar()
	}

	// Skip whitespace after "namespace"
	l.skipWhitespace()

	// Read the namespace name
	start := l.position
	for l.isLetter(l.ch) || (l.ch >= '0' && l.ch <= '9') || l.ch == '_' {
		l.readChar()
	}

	namespaceName := l.input[start:l.position]
	return Token{Type: NAMESPACE, Literal: namespaceName}
}

func (l *Lexer) readInstruction() Token {
	start := l.position
	for l.isLetter(l.ch) || (l.ch >= '0' && l.ch <= '9') {
		l.readChar()
	}
	return Token{Type: INSTRUCTION, Literal: l.input[start:l.position]}
}

func (l *Lexer) readOperand() Token {
	start := l.position
	for l.ch != ',' && l.ch != '\n' && l.ch != 0 && l.ch != SYMBOL_COMMENT_START {
		l.readChar()
	}
	return Token{Type: OPERAND, Literal: trimSpace(l.input[start:l.position])}
}

func trimSpace(s string) string {
	start, end := 0, len(s)
	for start < end && (s[start] == ' ' || s[start] == '\t') {
		start++
	}
	for end > start && (s[end-1] == ' ' || s[end-1] == '\t') {
		end--
	}
	return s[start:end]
}
